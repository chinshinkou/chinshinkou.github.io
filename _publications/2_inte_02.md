---
title: "Generating Virtual Head-Mounted Gyroscope Signals From Video Data"
collection: publications
category: international conference
permalink: /publication/inte_3
excerpt: 'Human activity recognition (HAR) using the deep learning method has caught...'
date: 2023-11-06
venue: 'International Conference on Consumer Electronics-Taiwan (ICCE-Taiwan)'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/10227010'
citation: 'M. Lu, C. Chen, B. Dawton, Y. Nakamura and Y. Arakawa, "Generating Virtual Head-Mounted Gyroscope Signals From Video Data," 2023 International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan), PingTung, Taiwan, 2023, pp. 273-274.'
---

Human activity recognition (HAR) using the deep learning method has caught the attention of researchers thanks to its automatic feature extraction and accurate prediction capabilities. However, for applications based on a wearable sensor, such as an inertial measurement unit (IMU), the process of collecting and hand-labeling large amounts of data is complicated and labor-intensive, meaning that there is a limited amount of data available for model training. Therefore, there is a need to propose and develop data augmentation approaches to generate high quality data for the growth of HAR research. We propose a head-mounted virtual gyroscope signal generator to alleviate the problems caused by the lack of data in head movement-related applications. Unlike previous work, our system only generates head-motion related gyroscope data, minimizing system complexity. We trained a deep-learning model in a head motion-based application with different generated sensor data ratios, and show the viability of our proposed data generation method.

